# 概要

voitter は、ツイートをラジオ感覚で楽しめるアプリケーションです。（一般公開の予定なし）
好きな twitter ユーザーのタイムラインを検索することができ、ツイートを音声で再生することが可能です。
自動再生機能を有しており、一度再生すると好きなだけ*1 ツイートを楽しむことができます。
再生音声は、日本語と英語が対応しており、日本語へ翻訳*2 することも可能です。

*1 実際には twitter api のリミットが存在します
*2 翻訳機能を利用するにはサインアップが必要です

フロントエンドのリポジトリ：voitter-fr
バックエンドのリポジトリ：voitter

### 背景

twitter は幅広い年代で利用されています*1。
twitter のインターフェースは、基本的に文字、映像、画像ですが、新たなインターフェースとして、ツイートを音声化することで、文字よりも音声の方が利用の難易度は低く、人々に馴染みやすいため、より多くの人に使ってもらえるサービスではないかと考えました。
*1 https://www.soumu.go.jp/main_content/000765258.pdf P.66

### インフラ図

![voitter-architecutre](https://user-images.githubusercontent.com/59119963/161428772-877932c4-8a03-4315-8322-8b33cae3487c.jpg)

### こだわった機能

voitter では以下に力を入れています。

- ユーザーへのストレス軽減
- ユーザーの安心感の確保

#### 自動再生、自動スクロール

- 多くのユーザーに長い時間使ってもらうために、 ユーザーの操作を極力減らし、ユーザーのストレスを減らしました。一度再生ボタンを押すと、定期的にタイムライン取得処理が実施され、音声が再生され続けます。（停止も可能です）また、現在再生されているツイートまで、自動スクロールされ中央に位置するため、目でツイートを確認したい場合も一目で把握可能です。

#### 翻訳

- 精度の高い翻訳を実施する\*1 ため、google 翻訳ではなく、deepL 翻訳を利用しました。
  明らかに変な翻訳は少なく、自然に理解できる日本語となっています。

\*1:https://www.deepl.com/press#press_comparison_article

#### セキュリティ

- ユーザーに安全に利用してもらう Web アプリケーションとするため以下を実施しました。

  - ログイン後の認証には、JWT を利用。JWT は、アクセストークン、リフレッシュトークンの２種類を使用。
    平時はアクセストークンを用いてアクセスしますが、アクセストークンが漏れた場合、リフレッシュトークンにより新規でアクセストークンを払い出します。
    リフレッシュトークンが漏れた場合、DB に保存しているユーザーに紐づくリフレッシュトークンを更新することで、漏れたリフレッシュトークンの被害を最小限に抑えます。他ユーザーへの影響はありません。
  - JWT は、Cookie に格納し、XSS に備えます。（Cookie は、HttpOnly, Secure）
  - Csrf トークンにより、csrf にも備えます。
  - ユーザーのロールによる認可機能を実装し、データの削除などのエンドポイントは、エンドユーザーからのリクエストを許可しません。
  - voitter のコンテンツは、CloudFront を通して配信されます。
    Cloudfront 経由でコンテンツを格納している S3 へアクセスする必要があり S3 へ直接アクセスは許可しません。
  - voitter の API は、AWS ECS 上で動作しますが、ECS へのアクセスは ALB 経由の８０ポートのみのアクセスで、SSH など、それ以外のアクセスは許可しません。

### 利用技術（何をなぜ使ったか）

以下を重要視し、技術選定を行なっております。

- ユーザーへのストレス軽減
- ユーザーの安心感の確保
- アプリケーション開発における生産性、保守性の向上

#### フロントエンド

- React
  ユーザーのストレスを減らすため、ページ遷移(遷移の度のページの取得)を行わない、SPA と希望しました\*1。
  Vue、Svelte も選択肢に挙がりましたが、React は Vue よりも世界的に利用されており、個人的にも使ってみたかったこと。また、フロントエンドの経験が浅い自分が作りきるには、日本語での情報が多い方が良いと考え、日本語の情報が少ない Svelte より、React を選択しました。

- ReduxToolkit
  データの流れが、一方向に流れるため、大きいアプリケーションでも拡張しやすいと考え採用しました。
  また、action, dispatch, state を定義する場所、利用する場所が自ずと決まるため、アプリケーションを作成していく中で、自然と見通しの良いコードとなりました。

- MaterialUI
  リリースされてからある程度使われている技術で、日本語での情報が多いため。

\*1: SPA 以外で、SSR, SSG, ISR も選択肢に挙がりましたが、更新があるアプリケーションということで、SSR, SSG は落選。ISR の挙動上、サーバーサイドのデータが更新されてから 2 回目のアクセスで、再ビルドしたページにアクセス可能となるため、voitter の特性上向いていない（勘違いあるかも？）と判断し、SPA となりました。

#### バックエンド

- NestJS(TypeScript)
  フロントエンドと同一の言語とすることで、生産性向上を期待し、NodeJS（Javascript）を採用しました。
  NodeJS のフレームワークでは、Express が候補に挙がりましたが、以下の理由で NestJS を採用しました。

  - Express より抽象化されている。（やるべきことの関心が少なく、ロジックに集中できるため）
  - TypeScript を完全にサポートしている。（型サポートで開発効率を高めるため）
  - DI(Data Injection)を標準でサポートしており、疎結合のため、拡張性が高まる。
    （Express より日本語の情報は少ないものの、今までのバックエンドの経験から完成することが可能と判断）

- MongoDB
  以下の理由で RDB ではなく NoSQL を採用しました。
  - 非正規化でデータを保持したい。(join はコストが高い)
  - 柔軟なスキーマを保持したい。(json をそのまま格納、json のキーを検索などの柔軟な用途が可能)
  - voitter では複雑なクエリや、トランザクションを必要としない。
    MongoDB の ORM が NestJS にプリインストールされていたため、MongoDB を採用しました。

#### インフラ

特に以下を意識しています。

- マネージドサービスを利用し、サーバの管理・運用の手間を減らす（ディスクサイズを増やしたり、パッチを適用する必要がない）
- AZ サービス/リージョンサービス/グローバルサービスを利用することで、AZ 障害に備え、スケーリングを容易にすることで、可用性を高める

- S3
  - 安価なストレージサービスであるため
- Cloudfront
  - React のコンテンツを HTTPS 通信とし、ユーザーに安全に利用してもらうため
  - エッジキャッシュを利用し、ユーザーに近いエッジネットワークからコンテンツを配信することでユーザーとのレイテンシを減らすため
- ALB
  - リクエストに応じ、アプリケーションを適切にスケールするため
- ECS(Fargate)
  - マネージドサービスでサーバの管理が不要なため
  - 環境間（ローカル/検証/商用 等）での環境差異を減らすため
- EFS
  - スケールする mongodb コンテナに対応するため（Fargate は EFS マウントが可能であり、各 Fargate は一つの EFS を共有できる）
  - RTO を小さくするため（ECS 障害時でも、データから復元するのではなく、EFS を再マウントするだけなの
    で、RTO を小さくできる）

### 技術的に困ったこと、解決方法

##### tweet の音声化の処理時間が長く、API のレスポンスに時間がかかる

voitter の api では、 twitter api, amazon polly api, deepL api と外部 api を利用しており、
外部 api の処理速度が遅く、改善が望めませんでした\*1。
そこで、voitter api で処理するツイートの件数を少なくし、API のレスポンスを早く返し、短いスパンでクライアントからリクエストを定期的に行うことで、ユーザーのストレスを軽減しています。
タイムライン再生中のツイート自動追加により、ユーザーは初期リクエスト以降ストレスを感じることがありません。

\*1 timline 5 件の処理で、 twitter api: 620ms, amazon polly api: 500ms, deepL api: 5000~10000ms ほどかかる。
元々、上記 api 以外に、polly での音声生成言語を識別する detection api を利用していたが、1 リクエスト 1000ms ほど時間がかかっていたため、音声生成言語を日本語、英語に限定し、日本語・英語の判定ロジックへと切り替えた。その結果、1 リクエスト 1ms 以下の処理速度となった。
